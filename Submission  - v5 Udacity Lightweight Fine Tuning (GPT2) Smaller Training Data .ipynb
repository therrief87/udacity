{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe951b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "import torch\n",
    "import huggingface\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, GPT2Model, GPT2Tokenizer, AutoModelForCausalLM,GPT2LMHeadModel, GPT2Config)\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be4d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import validation dataset for evaluation. \n",
    "dataset = load_dataset('rotten_tomatoes',split='validation') #just for evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe06abb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1066\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0bc5669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# get the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "# print output to the console\n",
    "print(current_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d9732a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#create tokenizer with padding\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "pad_token = \"<PAD>\"\n",
    "tokenizer.pad_token = pad_token\n",
    "#tokenizer.set_padding(tokenizer.pad_token, pad_to_multiple_of=8)\n",
    "config = GPT2Config.from_pretrained(\"gpt2\", pad_token_id=tokenizer.pad_token_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\",config=config)\n",
    "#config = GPT2Config.from_pretrained(\"gpt2\", pad_token_id=tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a119ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2038b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a tokenized dataset for evaluation\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97896cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating input for model\n",
    "inputs = tokenizer.encode_plus(\n",
    "    tokenized_datasets['text'],\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,  # Maximum sequence length\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f9edf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive (93.17%)\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities)\n",
    "\n",
    "# Display sentiment result\n",
    "if predicted_class == 1:\n",
    "    print(f\"Sentiment: Positive ({probabilities[0][1] * 100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"Sentiment: Negative ({probabilities[0][0] * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea862d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset labels\n",
    "labels = dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fdf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load full dataset for testing\n",
    "full_dataset = load_dataset('rotten_tomatoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7c3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader to efficiently process the data\n",
    "data_loader = torch.utils.data.DataLoader(list(zip(inputs[\"input_ids\"],inputs[\"attention_mask\"], labels)),\n",
    "batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8cc4c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pretrained model accuracy is 50.09 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate model performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tokenized_dataset = full_dataset.map(lambda examples: tokenizer(examples[\"text\"], padding=True, truncation=True))\n",
    "                                     #, batched=True)\n",
    "\n",
    "# Prepare the data for evaluation\n",
    "eval_dataset = tokenized_dataset[\"test\"].remove_columns([\"text\"]).rename_column(\"label\", \"labels\")\n",
    "eval_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "for batch in torch.utils.data.DataLoader(eval_dataset):\n",
    "    with torch.no_grad():\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "true_labels = eval_dataset[\"labels\"].numpy()\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"The pretrained model accuracy is\", round(accuracy*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dff021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PEFT Config for LoRA\n",
    "from peft import LoraConfig, TaskType\n",
    "config = LoraConfig(\n",
    "r=8, # Rank\n",
    "lora_alpha=32,\n",
    "target_modules=['c_attn', 'c_proj'],\n",
    "lora_dropout=0.1,\n",
    "bias=\"none\",\n",
    "task_type=TaskType.SEQ_CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99971e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\anaconda3\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:711: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#creating base peft model\n",
    "from peft import get_peft_model\n",
    "lora_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02120de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 812,544 || all params: 125,253,888 || trainable%: 0.6487175871139426\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b323b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a training dataset for PEFT model\n",
    "new_dataset = full_dataset.map(lambda examples: tokenizer(examples[\"text\"], padding=True, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36284730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "new_dataset = new_dataset.rename_column(\"label\", \"labels\")\n",
    "new_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e670fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unfreeze model\n",
    "for param in lora_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881786bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ec5d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training arguments for model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/felix/Documents/Udacity',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=4,\n",
    "    load_best_model_at_end=True,\n",
    "    #weight_decay=0.1,\n",
    "    remove_unused_columns=False,\n",
    "    #label_names=\"labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18bd8082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48c3600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce size of training data to speed up epochs\n",
    "n_samples =1500\n",
    "train_dataset = new_dataset['train']\n",
    "\n",
    "# Get the number of samples in the dataset\n",
    "num_samples = len(train_dataset)\n",
    "\n",
    "# Generate a list of random indices without replacement\n",
    "random_indices = random.sample(range(num_samples), n_samples)\n",
    "\n",
    "# Select the samples corresponding to the random indices\n",
    "random_train_samples = train_dataset.select(indices=random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15ae453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = torch.from_numpy(predictions)  # Convert predictions to tensor\n",
    "    labels = torch.from_numpy(labels).long()  # Convert labels to tensor\n",
    "    loss = nn.CrossEntropyLoss()(predictions, labels)  # Calculate the evaluation loss\n",
    "    accuracy = (torch.argmax(predictions, axis=1) == labels).float().mean()  # Calculate the accuracy\n",
    "\n",
    "    # Print the metrics dictionary for debugging\n",
    "    metrics = {\"eval_loss\": loss.item(), \"accuracy\": accuracy.item()}\n",
    "    print(\"Metrics:\", metrics)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b2ec776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:05:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.738780</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698363</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.588487</td>\n",
       "      <td>0.712008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.623600</td>\n",
       "      <td>0.722124</td>\n",
       "      <td>0.734522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'eval_loss': 0.7387796640396118, 'accuracy': 0.5}\n",
      "Metrics: {'eval_loss': 0.6983628273010254, 'accuracy': 0.5}\n",
      "Metrics: {'eval_loss': 0.5884869694709778, 'accuracy': 0.7120075225830078}\n",
      "Metrics: {'eval_loss': 0.7221236824989319, 'accuracy': 0.7345215678215027}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.6236490478515625, metrics={'train_runtime': 3965.3886, 'train_samples_per_second': 1.513, 'train_steps_per_second': 0.126, 'total_flos': 135987293491200.0, 'train_loss': 0.6236490478515625, 'epoch': 4.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args = training_args,\n",
    "    train_dataset = random_train_samples,\n",
    "    eval_dataset = new_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdb1b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 02:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'eval_loss': 0.5485303401947021, 'accuracy': 0.7363977432250977}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5485303401947021,\n",
       " 'eval_accuracy': 0.7363977432250977,\n",
       " 'eval_runtime': 153.1914,\n",
       " 'eval_samples_per_second': 6.959,\n",
       " 'eval_steps_per_second': 0.581,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1e7cb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review model\n",
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d16e8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "lora_model.save_pretrained('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "346ee8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f49f915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the saved model directory\n",
    "#model_dir = 'C:/Users/felix/Documents/Udacity/checkpoint-668/'\n",
    "\n",
    "# Load the saved PEFT model\n",
    "loaded_model = AutoPeftModelForSequenceClassification.from_pretrained('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74ab8fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "587aa3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset for inference\n",
    "imdb_dataset = load_dataset('imdb',split='test') #just for evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a6febe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the dataset smaller to reduce latency\n",
    "# Get the number of samples in the dataset\n",
    "n_samples = 500\n",
    "num_samples = len(imdb_dataset)\n",
    "\n",
    "# Generate a list of random indices without replacement\n",
    "random_indices = random.sample(range(num_samples), n_samples)\n",
    "\n",
    "# Select the samples corresponding to the random indices\n",
    "random_test_imdb = imdb_dataset.select(indices=random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04a94794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3fdcc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8377932bb9cc45baa58a4d1d31bd2929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenize imdb test dataset\n",
    "tokenized_imdb_dataset = random_test_imdb.map(lambda examples: tokenizer(examples[\"text\"], padding=True, truncation=True))\n",
    "                                     #, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1f82199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PEFT model model accuracy is 52.6 %\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for evaluation\n",
    "eval_imdb_dataset = tokenized_imdb_dataset.remove_columns([\"text\"]).rename_column(\"label\", \"labels\")\n",
    "eval_imdb_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "#evaluate with my PEFT model\n",
    "loaded_model.eval()\n",
    "predictions = []\n",
    "for batch in torch.utils.data.DataLoader(eval_imdb_dataset):\n",
    "    with torch.no_grad():\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = loaded_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "true_labels = eval_imdb_dataset[\"labels\"].numpy()\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(\"The PEFT model model accuracy is\", round(accuracy*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f378586d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pretrained model accuracy is 61.8 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate the original pretrained model\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "for batch in torch.utils.data.DataLoader(eval_imdb_dataset):\n",
    "    with torch.no_grad():\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "true_labels = eval_imdb_dataset[\"labels\"].numpy()\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"The pretrained model accuracy is\", round(accuracy*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6cabf",
   "metadata": {},
   "source": [
    "### Summary Thoughts\n",
    "\n",
    "- The pretrained model came out more accurate on an unseen dataset, when compared to my PEFT model. This is despite the opposite being true on my  original training dataset, which the PEFT model performed much better at. This could imply some overfitting was present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629cf75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
